{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_s6JqSW92MmR"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BmROD2Nw2iWy"
   },
   "source": [
    "##Transformer objects: \n",
    "\n",
    "These can each be used individually, or integrated into a pipeline.\n",
    "\n",
    "What is important is that they should be fit on the training data, and **not re-fit, but just used to transform** the testing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1QCANBot3Pzb"
   },
   "source": [
    "###SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lgLp88Eb2bM6"
   },
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer #This is very googleable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mO737z2T3XdP"
   },
   "outputs": [],
   "source": [
    "x1 = [1, 3, np.nan, 25, 1]\n",
    "x2  = [np.nan, np.nan, 2, 1, 3]\n",
    "x3 = [40, 24, np.nan, 13, 2]\n",
    "\n",
    "train = pd.DataFrame({'x1':x1, 'x2':x2, 'x3':x3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "H6ipVFwk34e7",
    "outputId": "861ad469-134b-4699-a3b4-e10fc7a01743"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1   x2    x3\n",
       "0   1.0  NaN  40.0\n",
       "1   3.0  NaN  24.0\n",
       "2   NaN  2.0   NaN\n",
       "3  25.0  1.0  13.0\n",
       "4   1.0  3.0   2.0"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OSQ5JW9737Iu"
   },
   "outputs": [],
   "source": [
    "x1_test = [135, 24, np.nan]\n",
    "x2_test = [np.nan, np.nan, np.nan]\n",
    "x3_test = [50, 135, np.nan]\n",
    "\n",
    "test = pd.DataFrame({'x1':x1_test, 'x2':x2_test, 'x3':x3_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "JTdtxvaD4Mo9",
    "outputId": "b72daf94-dab7-4812-bd92-9465258fd405"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1  x2     x3\n",
       "0  135.0 NaN   50.0\n",
       "1   24.0 NaN  135.0\n",
       "2    NaN NaN    NaN"
      ]
     },
     "execution_count": 66,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BTJy3JIe4QiN"
   },
   "source": [
    "Initialize a simpleimputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zy3pDS3U4Nkh"
   },
   "outputs": [],
   "source": [
    "imputer = SimpleImputer(strategy=\"median\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HN14lNMR4mIL"
   },
   "source": [
    "Here, the imputer is a blank slate. It hasn't yet learned the values it's supposed to impute for given columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "TQAJA1Qf4WwZ",
    "outputId": "ea2ed40e-72ed-45b9-9e14-078606ff183a"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-4da2f2b65839>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimputer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatistics_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'SimpleImputer' object has no attribute 'statistics_'"
     ]
    }
   ],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UvKbd72x4rzp"
   },
   "source": [
    "Here, we **fit** the imputer to our training data. THIS DOES NOT CHANGE THE TRAINING DATA IN ANY WAY, but the imputer has learned the values that it should impute for this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AVOmEuyw4YPw"
   },
   "outputs": [],
   "source": [
    "imputer.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FdmiPtHF4eh6"
   },
   "outputs": [],
   "source": [
    "imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "18LSrXzO40yh"
   },
   "outputs": [],
   "source": [
    "#Notice the unchanged training set. \n",
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wS4jNxPo40Eg"
   },
   "source": [
    "By using **.transform**, we can apply the transformation and **actually change the values of the training data.** Notice that this does not operate in place, and as such we must override the existing train memory location. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DmHS8KJ4hXB"
   },
   "outputs": [],
   "source": [
    "train = imputer.transform(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jREvtize5J6E"
   },
   "source": [
    "Also important to note is that sklearn transformations transform from a dataframe into a numpy array. This is for efficiency, and is what allows sklearn code to be so fast. However, it can cause problems for us down the line in identifying what variables we're actually looking at. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mRa8VIrH4_zV"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q_SvdWWl5AhR"
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "t9KMp_pt54K_"
   },
   "source": [
    "#### The last two steps we did can be combined. \n",
    "\n",
    "If we want to **fit (have the imputer learn what it's supposed to impute) and transform (actually change the values) at the same time...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y0QaLuF06Z-c"
   },
   "outputs": [],
   "source": [
    "x1 = [1, 3, np.nan, 25, 1]\n",
    "x2  = [np.nan, np.nan, 2, 1, 3]\n",
    "x3 = [40, 24, np.nan, 13, 2]\n",
    "\n",
    "train = pd.DataFrame({'x1':x1, 'x2':x2, 'x3':x3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4NLPg3TK52d8"
   },
   "outputs": [],
   "source": [
    "second_imputer = SimpleImputer(strategy=\"median\")\n",
    "\n",
    "train = second_imputer.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jpFIEpSK6ENh"
   },
   "outputs": [],
   "source": [
    "second_imputer.statistics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5fvWHxKx6Ia6"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AGvixur66lRW"
   },
   "source": [
    "#### .transform \n",
    "\n",
    "We can now use this to transform our test set according to our training set parameters. Crucially, this does **not** change the learned parameters of our imputer object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "H6vUXvU06JHf"
   },
   "outputs": [],
   "source": [
    "test = imputer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FtghtEnM6zic"
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rR399GCs6zy7"
   },
   "outputs": [],
   "source": [
    "imputer.statistics_ #Notice that these are the same as before. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SXmS_adJ7Fgs"
   },
   "source": [
    "### One more transformer example - StandardScaler\n",
    "\n",
    "Now that we've filled our missing values (which StandardScaler would have trouble with), we can implement our scaler. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wAYlpK0X614N"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i4qxnfMw7J6i"
   },
   "outputs": [],
   "source": [
    "#Initialize a scaler object \n",
    "\n",
    "our_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wpcNZ8H87NI3"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9wySbmOL86r-"
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dYZ47lov9p82"
   },
   "source": [
    "The pattern below is pretty representative of how we want to use transformers. To harp on this one more time, because it couldn't possible be more important: \n",
    "\n",
    "**learn parameters (fit) from the training data**.\n",
    "\n",
    "\n",
    "**transform both the training and testing data.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3URDs12q87g7"
   },
   "outputs": [],
   "source": [
    "train = our_scaler.fit_transform(train)\n",
    "test = our_scaler.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Fd1emv-i940P"
   },
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8KrKfMLB9-5L"
   },
   "outputs": [],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P2HG6P1J-BFK"
   },
   "source": [
    "Just like with imputer, we can get the statistics about the training data (the parameters that were \"fit\") reported back to us. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vUp9lw5c9_7g"
   },
   "outputs": [],
   "source": [
    "our_scaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DctRGmdp-LlL"
   },
   "outputs": [],
   "source": [
    "our_scaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lP2frDWF-NdQ"
   },
   "outputs": [],
   "source": [
    "our_scaler.var_**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TfcUwQjV-U8L"
   },
   "source": [
    "### Pipelines \n",
    "\n",
    "In a real use case, it'd be convenient if we could do all of our preprocessing in a consistent order that we can control, using one object. \n",
    "\n",
    "This is _much_ easier on us (a lot less typing and clicking) but also eliminates an enormous amount of potential for human error through running cells twice, in the wrong order, forgetting one or more, etc. \n",
    "\n",
    "This is where sklearn's **Pipeline** objects come into play. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wXpAxu7l-P7C"
   },
   "outputs": [],
   "source": [
    "x1 = [1, 3, np.nan, 25, 1]\n",
    "x2  = [np.nan, np.nan, 2, 1, 3]\n",
    "x3 = [40, 24, np.nan, 13, 2]\n",
    "\n",
    "train = pd.DataFrame({'x1':x1, 'x2':x2, 'x3':x3})\n",
    "\n",
    "x1_test = [135, 24, np.nan]\n",
    "x2_test = [np.nan, np.nan, np.nan]\n",
    "x3_test = [50, 135, np.nan]\n",
    "\n",
    "test = pd.DataFrame({'x1':x1_test, 'x2':x2_test, 'x3':x3_test})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7KP7tPaO-xvG"
   },
   "outputs": [],
   "source": [
    "#Import pipeline object \n",
    "from sklearn.pipeline import Pipeline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l_WkrH2d_MBU"
   },
   "source": [
    "Through the Pipeline constructor, we're able to give each transformer object a name. If you don't care to do this, you can use the make_pipeline convenience function, which will set default names. \n",
    "\n",
    "Pass in names and their associated transformers as a list of tuples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycIImkfa_JPg"
   },
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "                 ('imputer', SimpleImputer(strategy=\"median\")), \n",
    "                 ('scaler', StandardScaler())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PJimG1dv_1fl"
   },
   "source": [
    "The pipeline can now be treated like a transformer object itself, since it is compmosed exclusively of transformers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "quxKmgqV_qoQ"
   },
   "outputs": [],
   "source": [
    "train = pipe.fit_transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O81m0uP3_0WY"
   },
   "outputs": [],
   "source": [
    "test = pipe.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "4wf6JHh0_8G4",
    "outputId": "c10a2de2-4f7f-4368-988c-f5e7c7a7259b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1   x2    x3\n",
       "0   1.0  NaN  40.0\n",
       "1   3.0  NaN  24.0\n",
       "2   NaN  2.0   NaN\n",
       "3  25.0  1.0  13.0\n",
       "4   1.0  3.0   2.0"
      ]
     },
     "execution_count": 69,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 142
    },
    "colab_type": "code",
    "id": "PvKiTLL9_9J4",
    "outputId": "756f4d4c-634f-4739-9dfa-13e998f998d6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>135.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>135.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      x1  x2     x3\n",
       "0  135.0 NaN   50.0\n",
       "1   24.0 NaN  135.0\n",
       "2    NaN NaN    NaN"
      ]
     },
     "execution_count": 70,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cGHQ_dYPABMH"
   },
   "source": [
    "### Column transformers\n",
    "\n",
    "There's one big problem here, though. We really need to keep the operations we perform on numerical and categorical columns separate. \n",
    "\n",
    "Why? \n",
    "\n",
    "One-hot-encoding numerical variables seems like an extremely bad idea. We'd be treating continuous features as if they were categorical, and creating a new column for each unique value. Talk about the curse of dimensionality...\n",
    "\n",
    "Likewise, one-hot-encoding creates sparsity in the data. It doesn't make sense (is trivial, and might slow computation time through eliminating sparsity) to scale a column of ones and zeroes. \n",
    "\n",
    "Enter **ColumnTransformer**.\n",
    "\n",
    "It allows us to create multiple pipelines and specify which to apply to which features! Wonderful. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "f7ZVwZti_9Xp"
   },
   "outputs": [],
   "source": [
    "#To show what's going on, we need a new, multi type test dataframe.\n",
    "surface_area = [9910, 23000, 22300, 7340, 31700]\n",
    "elevation = [571, 577, 577, 246, np.nan]\n",
    "avg_depth = [62, np.nan, 279, 283, 483]\n",
    "lake_quality = [\"awesome\", \"meh\", \"meh\", np.nan, \"bad\"]\n",
    "\n",
    "lake = pd.DataFrame({'surface_area':surface_area, 'elevation':elevation, 'avg_depth':avg_depth, 'lake_quality':lake_quality})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "UOOnn2VnaGCX",
    "outputId": "950addbd-a639-4ae4-82b5-4f9adc0ea2f3"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surface_area</th>\n",
       "      <th>elevation</th>\n",
       "      <th>avg_depth</th>\n",
       "      <th>lake_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9910</td>\n",
       "      <td>571.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23000</td>\n",
       "      <td>577.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22300</td>\n",
       "      <td>577.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7340</td>\n",
       "      <td>246.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>483.0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surface_area  elevation  avg_depth lake_quality\n",
       "0          9910      571.0       62.0      awesome\n",
       "1         23000      577.0        NaN          meh\n",
       "2         22300      577.0      279.0          meh\n",
       "3          7340      246.0      283.0          NaN\n",
       "4         31700        NaN      483.0          bad"
      ]
     },
     "execution_count": 108,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NgM9Z7d-aLwq"
   },
   "outputs": [],
   "source": [
    "#Identify columns by type.\n",
    "numeric = lake.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "categorical = lake.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "TEsU1WZhaaeM",
    "outputId": "66dfe626-15e9-452d-ee63-4e3a6e7c8121"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['surface_area', 'elevation', 'avg_depth'], dtype='object')"
      ]
     },
     "execution_count": 110,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mo4lyZxDabtA",
    "outputId": "742d42c0-44e6-4ce7-baa0-c01447f4879d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lake_quality'], dtype='object')"
      ]
     },
     "execution_count": 111,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dfDjeH7Qat1S"
   },
   "source": [
    "Now, we can define two separate pipelines, differing by how we want to treat each subset of columns. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pYYhiuHDaxO8"
   },
   "outputs": [],
   "source": [
    "#NUMERIC PIPELINE: \n",
    "numeric_pipe = Pipeline(\n",
    "    [('imputer', SimpleImputer(strategy='median')), \n",
    "     ('scaler', StandardScaler())]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vU5mmHa8bCls"
   },
   "outputs": [],
   "source": [
    "#CATEGORICAL PIPELINE\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "categorical_pipe = Pipeline(\n",
    "    [('cat_imputer', SimpleImputer(strategy = 'most_frequent')), #Different null handling!\n",
    "     ('encoder', OneHotEncoder())]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r2I5C50Nbv8i"
   },
   "source": [
    "When using column transformer, the main argument is a list of tuples, just like for each individual pipeline. However, the tuples now have 3 args instead of 2. \n",
    "\n",
    "Name, transformer, features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-iaQrdf1bkXj"
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "full_transformer = ColumnTransformer(\n",
    "    transformers = [\n",
    "        ('numeric', numeric_pipe, numeric),\n",
    "        ('categorical', categorical_pipe, categorical)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sOq0SKRJcCCa"
   },
   "source": [
    "Now, use it as a transformer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J01GuYT-b-ic"
   },
   "outputs": [],
   "source": [
    "lake_processed = full_transformer.fit_transform(lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "PBZq0SyhcHw7",
    "outputId": "a4f9e657-a96c-4e0e-d3d6-cd3fc818149c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>surface_area</th>\n",
       "      <th>elevation</th>\n",
       "      <th>avg_depth</th>\n",
       "      <th>lake_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9910</td>\n",
       "      <td>571.0</td>\n",
       "      <td>62.0</td>\n",
       "      <td>awesome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23000</td>\n",
       "      <td>577.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22300</td>\n",
       "      <td>577.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>meh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7340</td>\n",
       "      <td>246.0</td>\n",
       "      <td>283.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31700</td>\n",
       "      <td>NaN</td>\n",
       "      <td>483.0</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   surface_area  elevation  avg_depth lake_quality\n",
       "0          9910      571.0       62.0      awesome\n",
       "1         23000      577.0        NaN          meh\n",
       "2         22300      577.0      279.0          meh\n",
       "3          7340      246.0      283.0          NaN\n",
       "4         31700        NaN      483.0          bad"
      ]
     },
     "execution_count": 115,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "5mVgay1Zds66",
    "outputId": "884380fc-3236-4005-fa2d-0c6dbbf6f692"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.991315</td>\n",
       "      <td>0.471415</td>\n",
       "      <td>-1.618582</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.460174</td>\n",
       "      <td>0.517036</td>\n",
       "      <td>0.025525</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.382554</td>\n",
       "      <td>0.517036</td>\n",
       "      <td>0.010510</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.276290</td>\n",
       "      <td>-1.999714</td>\n",
       "      <td>0.040540</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.424876</td>\n",
       "      <td>0.494226</td>\n",
       "      <td>1.542007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2    3    4    5\n",
       "0 -0.991315  0.471415 -1.618582  1.0  0.0  0.0\n",
       "1  0.460174  0.517036  0.025525  0.0  0.0  1.0\n",
       "2  0.382554  0.517036  0.010510  0.0  0.0  1.0\n",
       "3 -1.276290 -1.999714  0.040540  0.0  0.0  1.0\n",
       "4  1.424876  0.494226  1.542007  0.0  1.0  0.0"
      ]
     },
     "execution_count": 116,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(lake_processed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tH7wCQWGcL8y"
   },
   "source": [
    "This is exactly what we wanted! Expansion of our dummy variables without expansion (to maintain sparsity), while we scale the numeric features. \n",
    "\n",
    "This is also useful when you want to use a different imputation strategy across different columns, which we did here. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "54d7AwWIcaOF"
   },
   "source": [
    "#### Last note: including models in pipelines\n",
    "\n",
    "You can use the pipeline object to sequentially preprocess AND run your data — this makes it all happen in one cell, and is super awesome. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gR-sYhTRcIC6"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "model = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ykDNcVBDdHRP"
   },
   "outputs": [],
   "source": [
    "#We'll say this is our y variable that we're trying to predict using the preprocessed data in lake...\n",
    "\n",
    "y_train = [134, 245, 1630, 234, 984]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAS4ilybdT3B"
   },
   "outputs": [],
   "source": [
    "full_thing = Pipeline(steps = \n",
    "                      [('preprocessing', full_transformer), \n",
    "                       ('prediction', model)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ApiGOqefdhv9"
   },
   "source": [
    "Now instead of being a transformer (like our full_transformer and other pipelines were, this mega-pipeline is a MODEL — so, we fit and predict rather than fit and transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 578
    },
    "colab_type": "code",
    "id": "zLoQijRldeZ8",
    "outputId": "c5030800-1b85-4e85-a8b8-17f74cbc9fcd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('preprocessing',\n",
       "                 ColumnTransformer(n_jobs=None, remainder='drop',\n",
       "                                   sparse_threshold=0.3,\n",
       "                                   transformer_weights=None,\n",
       "                                   transformers=[('numeric',\n",
       "                                                  Pipeline(memory=None,\n",
       "                                                           steps=[('imputer',\n",
       "                                                                   SimpleImputer(add_indicator=False,\n",
       "                                                                                 copy=True,\n",
       "                                                                                 fill_value=None,\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='median',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('scaler',\n",
       "                                                                   StandardScaler(copy=True,\n",
       "                                                                                  with...\n",
       "                                                                                 missing_values=nan,\n",
       "                                                                                 strategy='most_frequent',\n",
       "                                                                                 verbose=0)),\n",
       "                                                                  ('encoder',\n",
       "                                                                   OneHotEncoder(categories='auto',\n",
       "                                                                                 drop=None,\n",
       "                                                                                 dtype=<class 'numpy.float64'>,\n",
       "                                                                                 handle_unknown='error',\n",
       "                                                                                 sparse=True))],\n",
       "                                                           verbose=False),\n",
       "                                                  Index(['lake_quality'], dtype='object'))],\n",
       "                                   verbose=False)),\n",
       "                ('prediction',\n",
       "                 LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "                                  normalize=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 133,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_thing.fit(lake, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "GRI4C68yd4W1",
    "outputId": "99ba9003-8175-4008-b540-6f1bd0ee7053"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 134.,  245., 1630.,  234.,  984.])"
      ]
     },
     "execution_count": 134,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_thing.predict(lake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HGvMPuise9MH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Sklearn transformers and pipelines.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
